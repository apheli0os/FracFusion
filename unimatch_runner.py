#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
UniMatchè®­ç»ƒè„šæœ¬ - é€‚ç”¨äºLinuxäº‘æœåŠ¡å™¨
æ”¯æŒåˆ†æ•°é˜¶å¢å¼ºå’Œè‡ªé€‚åº”ä¸Šé‡‡æ ·
"""

import os
import sys
import argparse
import subprocess
import shutil
import yaml
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from pathlib import Path
import re
import pathlib
import textwrap
from PIL import Image
from tqdm import tqdm
from scipy.special import gamma

def run_command(cmd, check=True, shell=False):
    """å®‰å…¨æ‰§è¡Œç³»ç»Ÿå‘½ä»¤"""
    try:
        if isinstance(cmd, str) and not shell:
            cmd = cmd.split()
        
        # å®æ—¶è¾“å‡ºï¼Œä¸ç¼“å†²
        process = subprocess.Popen(
            cmd, 
            stdout=subprocess.PIPE, 
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            bufsize=1
        )
        
        # å®æ—¶æ‰“å°è¾“å‡º
        for line in iter(process.stdout.readline, ''):
            print(line.rstrip())
        
        process.wait()
        
        if check and process.returncode != 0:
            raise subprocess.CalledProcessError(process.returncode, cmd)
            
        return process
        
    except subprocess.CalledProcessError as e:
        print(f"å‘½ä»¤æ‰§è¡Œå¤±è´¥: {cmd}")
        print(f"é”™è¯¯ä»£ç : {e.returncode}")
        if check:
            raise
        return e
class FractionalCoefficients:
    """åŸºäºå…¬å¼(18)çš„åˆ†æ•°é˜¶ç³»æ•°è®¡ç®—ç±»"""
    
    @staticmethod
    def compute_coefficients(v, max_order=10):
        """è®¡ç®—åˆ†æ•°é˜¶ç³»æ•° C_k"""
        coeffs = {}
        
        # åŸºäºæä¾›çš„å…¬å¼è®¡ç®—
        coeffs[-1] = v/4 + (v**2)/8                    # C_{-1}
        coeffs[0] = 1 - (v**2)/8 - (v**3)/8            # C_0  
        coeffs[1] = -5*v/4 + 5*(v**2)/16 + (v**4)/16   # C_1
        
        # é€šç”¨å…¬å¼è®¡ç®—æ›´é«˜é˜¶é¡¹
        for k in range(2, max_order + 1):
            try:
                c_k = (gamma(k-v+1) / (gamma(k+1) * gamma(-v))) * (v/4 + v**2/8)
                c_k += (gamma(k-v) / gamma(k+1)) * (1 - v**2/4)
                c_k += (gamma(k-v-1) / (gamma(k-1) * gamma(-v))) * (-v/4 + v**2/8)
                coeffs[k] = c_k
            except:
                coeffs[k] = coeffs[k-1] * (k-v) / k
        
        return coeffs

class FractionalMaskGenerator:
    """8æ–¹å‘åˆ†æ•°é˜¶æ©è†œç”Ÿæˆå™¨"""
    
    def __init__(self, v=0.5, mask_size=7):
        self.v = v
        self.mask_size = mask_size
        self.coeffs = FractionalCoefficients.compute_coefficients(v, mask_size//2)
        
    def generate_8_direction_masks(self):
        """ç”Ÿæˆ8ä¸ªæ–¹å‘çš„åˆ†æ•°é˜¶æ©è†œ"""
        masks = {}
        center = self.mask_size // 2
        
        # æ°´å¹³æ–¹å‘
        mask_h = torch.zeros(self.mask_size, self.mask_size)
        for i, coeff in self.coeffs.items():
            if abs(i) <= center:
                mask_h[center, center + i] = coeff
        masks['horizontal'] = mask_h
        
        # å‚ç›´æ–¹å‘
        mask_v = torch.zeros(self.mask_size, self.mask_size)
        for i, coeff in self.coeffs.items():
            if abs(i) <= center:
                mask_v[center + i, center] = coeff
        masks['vertical'] = mask_v
        
        # ä¸»å¯¹è§’çº¿æ–¹å‘
        mask_d1 = torch.zeros(self.mask_size, self.mask_size)
        for i, coeff in self.coeffs.items():
            if abs(i) <= center:
                if 0 <= center + i < self.mask_size and 0 <= center + i < self.mask_size:
                    mask_d1[center + i, center + i] = coeff
        masks['diagonal_main'] = mask_d1
        
        # åå¯¹è§’çº¿æ–¹å‘
        mask_d2 = torch.zeros(self.mask_size, self.mask_size)
        for i, coeff in self.coeffs.items():
            if abs(i) <= center:
                if 0 <= center + i < self.mask_size and 0 <= center - i < self.mask_size:
                    mask_d2[center + i, center - i] = coeff
        masks['diagonal_anti'] = mask_d2
        
        # é¢å¤–çš„4ä¸ªæ–¹å‘
        directions = ['northeast', 'northwest', 'southeast', 'southwest']
        offsets = [(-1, 1), (-1, -1), (1, 1), (1, -1)]
        
        for direction, (row_offset, col_offset) in zip(directions, offsets):
            mask = torch.zeros(self.mask_size, self.mask_size)
            for i, coeff in self.coeffs.items():
                if abs(i) <= center:
                    row, col = center + i * row_offset, center + i * col_offset
                    if 0 <= row < self.mask_size and 0 <= col < self.mask_size:
                        mask[row, col] = coeff
            masks[direction] = mask
        
        return masks

class FractionalImageEnhancer:
    """æ¨¡å—åŒ–åˆ†æ•°é˜¶å›¾åƒå¢å¼ºç±»"""
    
    def __init__(self, fractional_order=0.5, mask_size=7, enhancement_factor=0.3, enhancement_mode='weighted'):
        self.fractional_order = fractional_order
        self.mask_size = mask_size
        self.enhancement_factor = enhancement_factor
        self.enhancement_mode = enhancement_mode
        
        # ç”Ÿæˆåˆ†æ•°é˜¶æ©è†œ
        self.mask_generator = FractionalMaskGenerator(fractional_order, mask_size)
        self.masks = self.mask_generator.generate_8_direction_masks()
        
        # åŠ æƒå¢å¼ºçš„æ–¹å‘æƒé‡
        self.direction_weights = {
            'horizontal': 1.0, 'vertical': 1.0,
            'diagonal_main': 0.8, 'diagonal_anti': 0.8,
            'northeast': 0.6, 'northwest': 0.6,
            'southeast': 0.6, 'southwest': 0.6
        }
    
    def _preprocess_image(self, image):
        """å°†è¾“å…¥å›¾åƒé¢„å¤„ç†ä¸ºæ ‡å‡†æ ¼å¼"""
        if isinstance(image, np.ndarray):
            if image.dtype == np.uint8:
                image = image.astype(np.float32) / 255.0
            image = torch.from_numpy(image)
            
        if isinstance(image, Image.Image):
            image = torch.tensor(np.array(image), dtype=torch.float32) / 255.0
            
        # ç¡®ä¿æ­£ç¡®çš„å¼ é‡æ ¼å¼ [C, H, W]
        if len(image.shape) == 3:
            if image.shape[2] == 3:  # HWC æ ¼å¼
                image = image.permute(2, 0, 1)  # è½¬æ¢ä¸º CHW
        elif len(image.shape) == 2:  # ç°åº¦å›¾
            image = image.unsqueeze(0)  # æ·»åŠ é€šé“ç»´åº¦
            
        return image
    
    def _extract_directional_features(self, image):
        """æå–æ‰€æœ‰8ä¸ªæ–¹å‘çš„çº¹ç†ç‰¹å¾"""
        # è½¬æ¢ä¸ºç°åº¦å›¾è¿›è¡Œå¤„ç†
        if image.shape[0] == 3:  # RGB
            gray_image = torch.mean(image, dim=0, keepdim=True)
        else:
            gray_image = image
            
        # ä¸ºå·ç§¯æ·»åŠ æ‰¹æ¬¡ç»´åº¦
        gray_image = gray_image.unsqueeze(0)  # [1, 1, H, W]
        
        directional_features = {}
        
        # åº”ç”¨æ¯ä¸ªæ©è†œ
        for direction, mask in self.masks.items():
            conv_kernel = mask.unsqueeze(0).unsqueeze(0)  # [1, 1, mask_size, mask_size]
            padding = self.mask_size // 2
            
            # ä¸åˆ†æ•°é˜¶æ©è†œå·ç§¯
            feature = F.conv2d(gray_image, conv_kernel, padding=padding)
            directional_features[direction] = feature.squeeze()
            
        return directional_features
    
    def _combine_features(self, directional_features):
        """æ ¹æ®å¢å¼ºæ¨¡å¼ç»„åˆæ–¹å‘ç‰¹å¾"""
        feature_list = list(directional_features.values())
        
        if self.enhancement_mode == 'average':
            combined = torch.stack(feature_list).mean(dim=0)
            
        elif self.enhancement_mode == 'weighted':
            combined = torch.zeros_like(feature_list[0])
            total_weight = 0
            
            for direction, feature in directional_features.items():
                weight = self.direction_weights.get(direction, 1.0)
                combined += weight * feature
                total_weight += weight
                
            combined = combined / total_weight
            
        elif self.enhancement_mode == 'selective':
            feature_stack = torch.stack(feature_list)  # [8, H, W]
            variances = torch.var(feature_stack, dim=(1, 2))
            weights = F.softmax(variances * 10, dim=0)  # æ¸©åº¦ç¼©æ”¾
            
            combined = torch.zeros_like(feature_list[0])
            for i, feature in enumerate(feature_list):
                combined += weights[i] * feature
                
        else:
            raise ValueError(f"æœªçŸ¥çš„å¢å¼ºæ¨¡å¼: {self.enhancement_mode}")
            
        return combined
    
    def enhance_image(self, image):
        """ä¸»è¦å¢å¼ºå‡½æ•°"""
        # é¢„å¤„ç†è¾“å…¥
        original_image = self._preprocess_image(image)
        original_shape = original_image.shape
        
        # æå–æ–¹å‘ç‰¹å¾
        directional_features = self._extract_directional_features(original_image)
        
        # ç»„åˆç‰¹å¾
        enhancement_map = self._combine_features(directional_features)
        
        # åº”ç”¨å¢å¼º
        if len(original_shape) == 3:  # å½©è‰²å›¾åƒ
            enhanced_image = original_image.clone()
            for c in range(original_image.shape[0]):
                enhanced_image[c] += self.enhancement_factor * enhancement_map
        else:  # ç°åº¦å›¾
            enhanced_image = original_image + self.enhancement_factor * enhancement_map
            
        # å°†å€¼é™åˆ¶åœ¨æœ‰æ•ˆèŒƒå›´å†…
        enhanced_image = torch.clamp(enhanced_image, 0, 1)
        
        return enhanced_image, enhancement_map, directional_features

def setup_environment(args):
    """è®¾ç½®ç¯å¢ƒå’Œä¸‹è½½ä»£ç """
    print("ğŸš€ è®¾ç½®è®­ç»ƒç¯å¢ƒ...")
    
    # åˆ›å»ºå·¥ä½œç›®å½•
    work_dir = Path(args.work_dir)
    work_dir.mkdir(parents=True, exist_ok=True)
    os.chdir(work_dir)
    
    # å…‹éš†UniMatchä»“åº“
    unimatch_dir = work_dir / 'UniMatch'
    if not unimatch_dir.exists():
        print("ğŸ“¥ å…‹éš† UniMatch ä»“åº“...")
        run_command(f"git clone https://github.com/LiheYoung/UniMatch.git")
    else:
        print("âœ… UniMatch ä»“åº“å·²å­˜åœ¨")
    
    os.chdir(unimatch_dir)
    print(f"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
    
    # å®‰è£…ä¾èµ–
    if (unimatch_dir / 'requirements.txt').exists():
        print("ğŸ“¦ å®‰è£…ä¾èµ–åŒ…...")
        run_command("pip install -r requirements.txt")
    
    return unimatch_dir

def setup_pretrained_model(args, project_dir):
    """è®¾ç½®é¢„è®­ç»ƒæ¨¡å‹"""
    print("ğŸ“¥ è®¾ç½®é¢„è®­ç»ƒæ¨¡å‹...")
    
    pretrained_dir = project_dir / 'pretrained'
    pretrained_dir.mkdir(exist_ok=True)
    
    target_model_path = pretrained_dir / 'resnet101.pth'
    
    # æ£€æŸ¥é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
    if args.pretrained_path and Path(args.pretrained_path).exists():
        print(f"âœ… æ‰¾åˆ°é¢„è®­ç»ƒæ¨¡å‹: {args.pretrained_path}")
        shutil.copy2(args.pretrained_path, target_model_path)
        print(f"âœ… é¢„è®­ç»ƒæ¨¡å‹å·²å¤åˆ¶åˆ°: {target_model_path}")
        print(f"æ–‡ä»¶å¤§å°: {target_model_path.stat().st_size / (1024*1024):.1f} MB")
    else:
        print(f"âŒ æœªæ‰¾åˆ°é¢„è®­ç»ƒæ¨¡å‹æ–‡ä»¶: {args.pretrained_path}")
        print("è¯·ä¸‹è½½ ResNet101 é¢„è®­ç»ƒæ¨¡å‹åˆ°æŒ‡å®šè·¯å¾„")
        return False
    
    return True

def create_fractional_fusion_module(project_dir):
    """åˆ›å»ºåˆ†æ•°é˜¶èåˆæ¨¡å—"""
    print("ğŸ”§ åˆ›å»ºåˆ†æ•°é˜¶èåˆæ¨¡å—...")
    
    modules_dir = project_dir / 'model' / 'modules'
    modules_dir.mkdir(parents=True, exist_ok=True)
    
    fractional_fusion_path = modules_dir / 'fractional_fusion.py'
    
    content = '''
import torch
import torch.nn as nn
import torch.nn.functional as F

class FractionalFusionUp(nn.Module):
    """
    åˆ†æ•°é˜¶è‡ªé€‚åº”ä¸Šé‡‡æ ·ï¼ˆæ›¿ä»£æœ€ç»ˆ logits çš„åŒçº¿æ€§ä¸Šé‡‡æ ·ï¼‰
    - ä»…æ”¾å¤§ç©ºé—´ç»´åº¦ï¼Œä¸æ”¹å˜é€šé“æ•°
    - 8æ–¹å‘åˆ†æ•°é˜¶æ ¸ + é—¨æ§é«˜é€šå¢å¼º + ä½é€šæ®‹å·®èåˆ
    è¿”å›: y [B,C,H,W], orders [B,8,h,w], gate [B,1,H,W]
    """
    def __init__(self, in_channels, up_factor=4, kernel_size=3, vmax=1.0, hidden=48,
                 mode='both', beta=1.6, tau=0.5, center_bias=2.5, smooth_residual=0.15):
        super().__init__()
        self.k = int(kernel_size)
        self.s = int(up_factor)
        self.vmax = float(vmax)
        self.mode = mode
        self.center = self.k // 2
        self.beta = nn.Parameter(torch.tensor(float(beta)))
        self.tau = float(tau)
        self.center_bias = float(center_bias)
        self.smooth_residual = float(smooth_residual)

        # 8ä¸ªæ–¹å‘å•ä½å‘é‡
        dirs = torch.tensor([[1,0],[1,1],[0,1],[-1,1],[-1,0],[-1,-1],[0,-1],[1,-1]], dtype=torch.float32)
        self.register_buffer('dirs', dirs / (dirs.norm(dim=1, keepdim=True) + 1e-8))

        # é¢„æµ‹åˆ†æ•°é˜¶æ¬¡ä¸é—¨æ§ï¼ˆåœ¨ç±»åˆ«é€šé“ä¸Šï¼‰
        self.order_head = nn.Sequential(
            nn.Conv2d(in_channels, hidden, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(hidden, 8, 3, 1, 1)
        )
        self.gate = nn.Sequential(
            nn.Conv2d(in_channels, hidden, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(hidden, 1, 3, 1, 1), nn.Sigmoid()
        )

        # é¢„è®¡ç®—æ–¹å‘-æ­¥é•¿åŸºåº• [8,2,M+1,K,K]
        base = []
        with torch.no_grad():
            yy, xx = torch.meshgrid(torch.arange(self.k), torch.arange(self.k), indexing='ij')
            rel = torch.stack([yy - self.center, xx - self.center], dim=-1).float()
            max_m = self.center
            for d in range(8):
                v = self.dirs[d]
                proj = rel[..., 0] * v[1] + rel[..., 1] * v[0]
                step = proj.round().clamp(min=-max_m, max=max_m).int()
                pos_masks, neg_masks = [], []
                for m in range(max_m + 1):
                    pos_masks.append((step == m).float())
                    neg_masks.append((step == -m).float())
                base.append(torch.stack(pos_masks, 0))
                base.append(torch.stack(neg_masks, 0))
        dir_step_base = torch.stack([torch.stack(base[2*i:2*i+2], 0) for i in range(8)], 0)
        self.register_buffer('dir_step_base', dir_step_base)

    @staticmethod
    def gl_coeffs(v, M):
        # Grunwaldâ€“Letnikov ç³»æ•°
        if v.dim() == 3:
            v = v.unsqueeze(1)
        B, _, H, W = v.shape
        coeffs = [torch.ones(B,1,H,W, device=v.device, dtype=v.dtype)]
        w = coeffs[0]
        for m in range(1, M+1):
            w = w * (v - m + 1.0)/m * (-1.0)
            coeffs.append(w)
        return torch.cat(coeffs, dim=1)  # [B,M+1,H,W]

    def _direction_kernel(self, v_dir, d):
        M = self.center
        coeff = self.gl_coeffs(v_dir, M)  # [B,M+1,H,W]
        base_pos = self.dir_step_base[d,0]  # [M+1,K,K]
        base_neg = self.dir_step_base[d,1]  # [M+1,K,K]
        ker = (coeff[:, :, None, None, ...] *
               (base_pos[None, :, :, :, None, None] - base_neg[None, :, :, :, None, None])).sum(1)
        return ker  # [B,K,K,H,W]

    def _build_kernels(self, v):
        # 8æ–¹å‘å–å‡å€¼
        ks = [self._direction_kernel(v[:, d:d+1], d) for d in range(8)]
        return torch.stack(ks, 0).mean(0)  # [B,K,K,H,W]

    def forward(self, x):
        B, C, h, w = x.shape
        raw_v = self.order_head(x)
        g = self.gate(x)                         # [B,1,h,w]
        v = self.vmax * torch.tanh(raw_v)        # [B,8,h,w]
        ker = self._build_kernels(v)             # [B,K,K,h,w]
        K, pad = self.k, self.center

        # ä½é€šæƒé‡ï¼ˆä¸­å¿ƒåç½® + æ¸©åº¦ softmaxï¼‰
        mask_pre = ker.view(B, K*K, h, w)
        center_idx = self.center * self.k + self.center
        mask_pre[:, center_idx:center_idx+1] = mask_pre[:, center_idx:center_idx+1] + self.center_bias
        mask_lp = torch.softmax(mask_pre / self.tau, dim=1)  # [B,K^2,h,w]

        # é‚»åŸŸå±•å¼€
        xp = F.pad(x, [pad, pad, pad, pad], mode='reflect')
        patches = F.unfold(xp, kernel_size=K, stride=1, padding=0).view(B, C, K*K, h, w)

        # æ”¾å¤§ç©ºé—´ç»´ï¼ˆä»…ç©ºé—´ï¼Œä¿ç•™é€šé“ï¼‰
        if self.s > 1:
            neigh   = patches.repeat_interleave(self.s, dim=3).repeat_interleave(self.s, dim=4)  # [B,C,K^2,H,W]
            mask_lp = mask_lp.repeat_interleave(self.s, dim=2).repeat_interleave(self.s, dim=3)  # [B,K^2,H,W]
            g_up    = g.repeat_interleave(self.s, dim=2).repeat_interleave(self.s, dim=3)        # [B,1,H,W]
            x_up    = F.interpolate(x, scale_factor=self.s, mode='bilinear', align_corners=False) # [B,C,H,W]
        else:
            neigh, g_up, x_up = patches, g, x

        # ä½é€šè¾“å‡º + è¾¹ç¼˜è‡ªé€‚åº”æ®‹å·®ï¼ˆé™ä½æ¨¡ç³Šï¼‰
        y_lp_out = (neigh * mask_lp[:, None]).sum(dim=2)
        lambda_eff = self.smooth_residual * (1.0 - g_up)
        y_lp = x_up + lambda_eff * (y_lp_out - x_up)

        if self.mode == 'lowpass':
            return y_lp, v, g_up

        # é«˜é€šï¼ˆé›¶ç›´æµ + L1å½’ä¸€ï¼‰
        ker_hp = ker - ker.mean(dim=(1, 2), keepdim=True)
        ker_hp = ker_hp / (ker_hp.abs().sum(dim=(1, 2), keepdim=True) + 1e-8)
        mask_hp = ker_hp.view(B, K*K, h, w)
        if self.s > 1:
            mask_hp = mask_hp.repeat_interleave(self.s, dim=2).repeat_interleave(self.s, dim=3)
        y_hp = (neigh * mask_hp[:, None]).sum(dim=2)

        if self.mode == 'highpass':
            return y_hp, v, g_up

        # èåˆ
        y = y_lp + torch.tanh(self.beta) * g_up * y_hp
        return y, v, g_up
'''
    
    fractional_fusion_path.write_text(content.strip(), encoding='utf-8')
    print(f'âœ… å·²ç”Ÿæˆ: {fractional_fusion_path}')
    
    return True

def patch_deeplabv3plus(project_dir):
    """ä¿®è¡¥DeepLabV3Plusä»¥æ”¯æŒåˆ†æ•°é˜¶ä¸Šé‡‡æ ·"""
    print("ğŸ”§ ä¿®è¡¥ DeepLabV3Plus...")
    
    # æŸ¥æ‰¾ deeplabv3plus.py
    target = None
    for root, _, files in os.walk(project_dir / 'model'):
        for f in files:
            if f.lower() == 'deeplabv3plus.py' and 'semseg' in str(root):
                target = Path(root) / f
                break
        if target: break
    
    if not target or not target.exists():
        print(f'âŒ æœªæ‰¾åˆ° deeplabv3plus.py')
        return False
    
    print(f'ç›®æ ‡æ–‡ä»¶: {target}')
    
    # å¤‡ä»½åŸæ–‡ä»¶
    backup = target.with_suffix(target.suffix + '.bak')
    if backup.exists():
        # ä»å¤‡ä»½æ¢å¤
        shutil.copy2(backup, target)
    else:
        # åˆ›å»ºå¤‡ä»½
        shutil.copy2(target, backup)
    
    src = target.read_text(encoding='utf-8')
    
    # ç»Ÿä¸€ç¼©è¿›å’Œè¡Œå°¾
    src = src.replace('\r\n', '\n').replace('\r', '\n').replace('\t', '    ')
    
    # ç¡®ä¿æœ‰å¿…è¦çš„å¯¼å…¥
    if 'import torch.nn.functional as F' not in src:
        if 'from torch import nn' in src:
            src = src.replace('from torch import nn', 'from torch import nn\nimport torch.nn.functional as F')
        else:
            src = 'import torch.nn.functional as F\n' + src
    
    if 'from model.modules.fractional_fusion import FractionalFusionUp' not in src:
        src = src.replace(
            'import torch.nn.functional as F',
            'import torch.nn.functional as F\nfrom model.modules.fractional_fusion import FractionalFusionUp'
        )
    
    # æ‰¾åˆ° DeepLabV3Plus ç±»
    class_pat = re.compile(r'\nclass\s+DeepLabV3Plus\s*\(.*?\)\s*:\s*\n', re.S)
    m = class_pat.search(src)
    if not m:
        print('âŒ æœªæ‰¾åˆ°ç±» DeepLabV3Plus å®šä¹‰')
        return False
    
    cls_start = m.end()
    
    # æŸ¥æ‰¾ç±»ç»“æŸ
    tail_pat = re.compile(r'\n(class\s+|def\s+)', re.S)
    m_end = tail_pat.search(src, cls_start)
    cls_end = m_end.start()+1 if m_end else len(src)
    
    cls_block = src[cls_start:cls_end]
    
    # æ³¨å…¥ _up æ–¹æ³•ï¼ˆè‹¥ä¸å­˜åœ¨ï¼‰
    if 'def _up(' not in cls_block:
        # ä¼°è®¡ç±»ä½“ç¼©è¿›
        lines_after = cls_block.splitlines()
        indent_cls = '    '
        for ln in lines_after:
            if ln.strip():
                indent_cls = ln[:len(ln)-len(ln.lstrip(' '))] or '    '
                break
        
        up_code = textwrap.dedent("""
        def _up(self, t, size=None, scale_factor=None, mode="bilinear", align_corners=False):
            \"\"\"ä»…å½“é€šé“æ•°ç­‰äºç±»åˆ«æ•°æ—¶å¯ç”¨åˆ†æ•°é˜¶ä¸Šé‡‡æ ·ï¼›å¦åˆ™å›é€€åŒçº¿æ€§\"\"\"
            try:
                nclass = getattr(self, "nclass", None)
                if nclass is None and hasattr(self, "classifier"):
                    nclass = getattr(self.classifier, "out_channels", None)
                if nclass is None:
                    nclass = t.shape[1]
                is_logits = (t.shape[1] == nclass)

                if is_logits:
                    # æ‡’åˆå§‹åŒ–åˆ†æ•°é˜¶ä¸Šé‡‡æ ·
                    if not hasattr(self, "frac_up") or self.frac_up is None:
                        if scale_factor is not None:
                            s = int(scale_factor)
                        elif size is not None:
                            tgt_h = size[0] if isinstance(size, (list, tuple)) else size
                            s = max(1, int(round(tgt_h / t.shape[-2])))
                        else:
                            s = 4
                        s = max(1, s)
                        self.frac_up = FractionalFusionUp(
                            in_channels=nclass, up_factor=s, kernel_size=3,
                            vmax=1.0, hidden=48, mode="both", beta=1.6,
                            tau=0.5, center_bias=2.5, smooth_residual=0.15
                        )
                    y, _, _ = self.frac_up(t)
                    if size is not None and tuple(y.shape[-2:]) != tuple(size):
                        y = F.interpolate(y, size=size, mode=mode, align_corners=align_corners)
                    return y
            except Exception:
                # ä»»æ„å¼‚å¸¸éƒ½å›é€€åŒçº¿æ€§ï¼Œä¿è¯è®­ç»ƒä¸è¢«æ‰“æ–­
                pass
            return F.interpolate(t, size=size, scale_factor=scale_factor, mode=mode, align_corners=align_corners)
        """).strip('\n')
        
        # ç¼©è¿›åˆ°ç±»ä½“
        up_code_indented = '\n'.join(
            (indent_cls + ln) if ln.strip() else ln
            for ln in up_code.splitlines()
        )
        # æ’åˆ°ç±»ä½“å¼€å¤´
        cls_block = up_code_indented + '\n\n' + cls_block
    
    # ä»…åœ¨ç±»ä½“å†…å°† F.interpolate( æ›¿æ¢ä¸º self._up(
    cls_block = re.sub(r'\bF\.interpolate\s*\(', 'self._up(', cls_block)
    
    # ä¿®å¤ _up æ–¹æ³•å†…è¢«è¯¯æ›¿æ¢çš„è°ƒç”¨
    up_method_pattern = r'(def\s+_up\s*\(.*?\):\s*)([\s\S]*?)(?=\n\s{4}def\s+|\n\s*class\s+|\Z)'
    m_up = re.search(up_method_pattern, cls_block)
    if m_up:
        head, body = m_up.group(1), m_up.group(2)
        fixed_body = re.sub(r'\bself\._up\s*\(', 'F.interpolate(', body)
        cls_block = cls_block[:m_up.start(2)] + fixed_body + cls_block[m_up.end(2):]
    
    # å›å†™æ–‡ä»¶
    new_src = src[:cls_start] + cls_block + src[cls_start+len(src[cls_start:cls_end]):]
    target.write_text(new_src, encoding='utf-8')
    print('âœ… DeepLabV3Plus ä¿®è¡¥å®Œæˆ')
    
    return True

def fix_torch_load_compatibility(project_dir):
    """ä¿®å¤PyTorch 2.6å…¼å®¹æ€§é—®é¢˜"""
    print("ğŸ”§ ä¿®å¤ torch.load å…¼å®¹æ€§...")
    
    python_files = []
    for root, dirs, files in os.walk(project_dir):
        for file in files:
            if file.endswith('.py'):
                python_files.append(Path(root) / file)
    
    print(f"æ£€æŸ¥ {len(python_files)} ä¸ªPythonæ–‡ä»¶...")
    
    fixed_files = []
    for file_path in python_files:
        try:
            content = file_path.read_text(encoding='utf-8')
            original_content = content
            
            # æ›´ç²¾ç¡®çš„æ­£åˆ™è¡¨è¾¾å¼ï¼ŒåªåŒ¹é…çœŸæ­£çš„torch.loadè°ƒç”¨
            # åŒ¹é… torch.load(å‚æ•°) ä½†ä¸åŒ¹é…åœ¨å…¶ä»–å‡½æ•°è°ƒç”¨å†…éƒ¨çš„æƒ…å†µ
            pattern = r'torch\.load\s*\(\s*([^)]+)\s*\)'
            
            def fix_weights_only(match):
                args_str = match.group(1).strip()
                
                # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰weights_onlyå‚æ•°
                if 'weights_only' in args_str:
                    return match.group(0)  # å·²ç»æœ‰äº†ï¼Œä¸ä¿®æ”¹
                
                # ç¡®ä¿è¿™ä¸æ˜¯åœ¨å…¶ä»–å‡½æ•°è°ƒç”¨å†…éƒ¨
                # å¦‚æœå‚æ•°ä¸­åŒ…å«å‡½æ•°è°ƒç”¨ï¼Œéœ€è¦æ›´ä»”ç»†å¤„ç†
                if args_str.count('(') != args_str.count(')'):
                    return match.group(0)  # å¯èƒ½æ˜¯åµŒå¥—è°ƒç”¨ï¼Œè·³è¿‡
                
                # æ·»åŠ weights_onlyå‚æ•°
                if args_str.strip():
                    args_str += ', weights_only=False'
                else:
                    args_str = 'weights_only=False'
                
                return f'torch.load({args_str})'
            
            # åº”ç”¨ä¿®å¤
            new_content = re.sub(pattern, fix_weights_only, content)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å˜åŒ–
            if new_content != original_content:
                file_path.write_text(new_content, encoding='utf-8')
                fixed_files.append(file_path)
                
        except Exception as e:
            print(f"âš ï¸  æ— æ³•å¤„ç†æ–‡ä»¶ {file_path}: {e}")
    
    print(f"âœ… å·²ä¿®å¤ {len(fixed_files)} ä¸ªæ–‡ä»¶")
    return True

def update_config(args, project_dir):
    """æ›´æ–°é…ç½®æ–‡ä»¶"""
    print("ğŸ”§ æ›´æ–°é…ç½®æ–‡ä»¶...")
    
    config_path = project_dir / 'configs' / 'pascal.yaml'
    
    with open(config_path, 'r') as f:
        config_data = yaml.safe_load(f)
    
    # æ›´æ–°åŸºæœ¬é…ç½®
    config_data.update({
        'data_root': str(args.data_root),
        'batch_size': args.batch_size,
        'backbone': 'resnet101',
        'lr': args.lr,
        'crop_size': 321,
        'nclass': 21,
        'num_workers': args.num_workers,
        'pin_memory': True,
        'persistent_workers': True,
        'prefetch_factor': 4,
        'eval_freq': args.eval_freq,
        'epochs': args.epochs,
    })
    
    # æ·»åŠ åˆ†æ•°é˜¶ç›¸å…³é…ç½®
    config_data.update({
        'use_fractional_up': True,
        'frac_up_factor': 4,
        'frac_kernel_size': 3,
        'frac_vmax': 1.0,
        'frac_beta': 1.6,
        'frac_hidden': 48,
        'frac_tau': 0.5,
        'frac_center_bias': 2.5,
        'frac_smooth_residual': 0.15
    })
    
    with open(config_path, 'w') as f:
        yaml.dump(config_data, f)
    
    print("âœ… é…ç½®æ–‡ä»¶æ›´æ–°å®Œæˆ")
    return config_data

def preprocess_dataset_with_fractional_enhancement(args, project_dir):
    """å¯¹æ•´ä¸ªæ•°æ®é›†è¿›è¡Œåˆ†æ•°é˜¶å¢å¼ºé¢„å¤„ç†"""
    if not args.enable_fractional_enhancement:
        print("è·³è¿‡åˆ†æ•°é˜¶å¢å¼ºé¢„å¤„ç†")
        return args.data_root
    
    print("ğŸš€ å¼€å§‹å¯¹æ•°æ®é›†è¿›è¡Œåˆ†æ•°é˜¶å¢å¼ºé¢„å¤„ç†...")
    
    original_data_root = Path(args.data_root)
    enhanced_data_root = project_dir.parent / 'enhanced_VOC2012'
    
    original_img_dir = original_data_root / 'JPEGImages'
    enhanced_img_dir = enhanced_data_root / 'JPEGImages'
    
    # åˆ›å»ºå¢å¼ºåçš„æ•°æ®ç›®å½•
    enhanced_img_dir.mkdir(parents=True, exist_ok=True)
    
    # å¤åˆ¶å…¶ä»–å¿…è¦ç›®å½•
    for dir_name in ['SegmentationClass', 'SegmentationObject', 'ImageSets']:
        src_dir = original_data_root / dir_name
        dst_dir = enhanced_data_root / dir_name
        if src_dir.exists():
            if dst_dir.exists():
                shutil.rmtree(dst_dir)
            shutil.copytree(src_dir, dst_dir)
            print(f"âœ… å¤åˆ¶ç›®å½•: {dir_name}")
    
    # åˆå§‹åŒ–åˆ†æ•°é˜¶å¢å¼ºå™¨
    enhancer = FractionalImageEnhancer(
        fractional_order=0.6,
        enhancement_factor=0.2,
        enhancement_mode='weighted'
    )
    
    # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
    img_files = [f for f in original_img_dir.iterdir() 
                 if f.suffix.lower() in ['.jpg', '.jpeg', '.png']]
    
    print(f"æ‰¾åˆ° {len(img_files)} å¼ å›¾åƒéœ€è¦å¤„ç†")
    
    # æ‰¹é‡å¤„ç†å›¾åƒ
    processed_count = 0
    failed_count = 0
    
    for img_file in tqdm(img_files, desc="å¤„ç†å›¾åƒ"):
        try:
            # åŠ è½½åŸå§‹å›¾åƒ
            original_img = Image.open(img_file).convert('RGB')
            
            # åº”ç”¨åˆ†æ•°é˜¶å¢å¼º
            enhanced_tensor, _, _ = enhancer.enhance_image(original_img)
            
            # è½¬æ¢å›PILå›¾åƒ
            enhanced_array = (enhanced_tensor.permute(1, 2, 0).numpy() * 255).astype('uint8')
            enhanced_img = Image.fromarray(enhanced_array)
            
            # ä¿å­˜å¢å¼ºåçš„å›¾åƒ
            enhanced_path = enhanced_img_dir / img_file.name
            enhanced_img.save(enhanced_path, quality=95)
            
            processed_count += 1
            
        except Exception as e:
            print(f"âŒ å¤„ç†å›¾åƒå¤±è´¥ {img_file.name}: {str(e)}")
            failed_count += 1
            
            # å¦‚æœå¢å¼ºå¤±è´¥ï¼Œå¤åˆ¶åŸå›¾åƒ
            try:
                shutil.copy2(img_file, enhanced_img_dir / img_file.name)
                processed_count += 1
            except:
                pass
    
    print(f"\nâœ… é¢„å¤„ç†å®Œæˆ:")
    print(f"   æˆåŠŸå¤„ç†: {processed_count} å¼ å›¾åƒ")
    print(f"   å¤±è´¥: {failed_count} å¼ å›¾åƒ")
    print(f"   å¢å¼ºåæ•°æ®é›†ä½ç½®: {enhanced_data_root}")
    
    return enhanced_data_root

def start_training(args, project_dir):
    """å¯åŠ¨è®­ç»ƒ"""
    print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
    
    # è®¾ç½®è®­ç»ƒå‚æ•°
    dataset = 'pascal'
    method = 'unimatch'
    exp = 'r101'
    split = '732'
    
    config_file_path = f'configs/{dataset}.yaml'
    labeled_id_path = f'splits/{dataset}/{split}/labeled.txt'
    unlabeled_id_path = f'splits/{dataset}/{split}/unlabeled.txt'
    save_path = args.save_path or str(project_dir.parent / 'exp' / dataset / method / exp / split)
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    Path(save_path).mkdir(parents=True, exist_ok=True)
    
    # éªŒè¯å…³é”®æ–‡ä»¶å­˜åœ¨
    files_to_check = [
        f'{method}.py',
        config_file_path,
        labeled_id_path,
        unlabeled_id_path
    ]
    
    print("\néªŒè¯å…³é”®æ–‡ä»¶:")
    for file_path in files_to_check:
        if Path(file_path).exists():
            print(f"âœ… {file_path}")
        else:
            print(f"âŒ {file_path} - æœªæ‰¾åˆ°!")
            return False
    
    # æ„å»ºè®­ç»ƒå‘½ä»¤ - å³ä½¿å•GPUä¹Ÿè¦ç”¨torchrun
    cmd = [
        "torchrun",
        f"--nproc_per_node={args.num_gpus}",
        f"--master_port={args.port}",
        "--nnodes=1",
        "--node_rank=0",
        f"{method}.py",
        "--config", config_file_path,
        "--labeled-id-path", labeled_id_path,
        "--unlabeled-id-path", unlabeled_id_path,
        "--save-path", save_path,
        "--port", str(args.port)
    ]
    
    print(f"\nä½¿ç”¨ {args.num_gpus} ä¸ª GPU è¿›è¡Œè®­ç»ƒ...")
    print(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
    
    # å¯åŠ¨è®­ç»ƒ
    try:
        result = run_command(cmd)
        print("âœ… è®­ç»ƒå®Œæˆ")
        return True
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        return False

def main():
    parser = argparse.ArgumentParser(description='UniMatchè®­ç»ƒè„šæœ¬ - æ”¯æŒåˆ†æ•°é˜¶å¢å¼º')
    
    # åŸºæœ¬å‚æ•°
    parser.add_argument('--work-dir', type=str, default='/root/autodl-tmp/unimatch_workspace',
                       help='å·¥ä½œç›®å½•è·¯å¾„')
    parser.add_argument('--data-root', type=str, required=True,
                       help='æ•°æ®é›†æ ¹ç›®å½•è·¯å¾„')
    parser.add_argument('--pretrained-path', type=str, 
                       help='é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ (resnet101.pth)')
    parser.add_argument('--save-path', type=str,
                       help='æ¨¡å‹ä¿å­˜è·¯å¾„')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--batch-size', type=int, default=6,
                       help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--lr', type=float, default=0.004,
                       help='å­¦ä¹ ç‡')
    parser.add_argument('--epochs', type=int, default=80,
                       help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--eval-freq', type=int, default=5,
                       help='éªŒè¯é¢‘ç‡')
    parser.add_argument('--num-workers', type=int, default=6,
                       help='æ•°æ®åŠ è½½å·¥ä½œè¿›ç¨‹æ•°')
    parser.add_argument('--num-gpus', type=int, default=1,
                       help='ä½¿ç”¨çš„GPUæ•°é‡')
    parser.add_argument('--port', type=int, default=12345,
                       help='åˆ†å¸ƒå¼è®­ç»ƒç«¯å£')
    
    # åˆ†æ•°é˜¶å¢å¼ºå‚æ•°
    parser.add_argument('--enable-fractional-enhancement', action='store_true',
                       help='å¯ç”¨åˆ†æ•°é˜¶å¢å¼ºé¢„å¤„ç†')
    
    # æµç¨‹æ§åˆ¶
    parser.add_argument('--skip-setup', action='store_true',
                       help='è·³è¿‡ç¯å¢ƒè®¾ç½®')
    parser.add_argument('--skip-preprocessing', action='store_true',
                       help='è·³è¿‡æ•°æ®é¢„å¤„ç†')
    parser.add_argument('--skip-training', action='store_true',
                       help='è·³è¿‡è®­ç»ƒï¼ˆä»…è®¾ç½®ç¯å¢ƒï¼‰')
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("ğŸ¯ UniMatch åˆ†æ•°é˜¶å¢å¼ºè®­ç»ƒè„šæœ¬")
    print("=" * 60)
    print(f"å·¥ä½œç›®å½•: {args.work_dir}")
    print(f"æ•°æ®æ ¹ç›®å½•: {args.data_root}")
    print(f"æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    print(f"å­¦ä¹ ç‡: {args.lr}")
    print(f"GPUæ•°é‡: {args.num_gpus}")
    print(f"åˆ†æ•°é˜¶å¢å¼º: {'å¯ç”¨' if args.enable_fractional_enhancement else 'ç¦ç”¨'}")
    print("=" * 60)
    
    try:
        # Step 1: è®¾ç½®ç¯å¢ƒ
        if not args.skip_setup:
            project_dir = setup_environment(args)
            
            # è®¾ç½®é¢„è®­ç»ƒæ¨¡å‹
            if args.pretrained_path:
                if not setup_pretrained_model(args, project_dir):
                    print("âŒ é¢„è®­ç»ƒæ¨¡å‹è®¾ç½®å¤±è´¥")
                    return 1
            
            # åˆ›å»ºåˆ†æ•°é˜¶èåˆæ¨¡å—
            create_fractional_fusion_module(project_dir)
            
            # ä¿®è¡¥DeepLabV3Plus
            patch_deeplabv3plus(project_dir)
            
            # ä¿®å¤PyTorchå…¼å®¹æ€§
            fix_torch_load_compatibility(project_dir)
            
        else:
            project_dir = Path(args.work_dir) / 'UniMatch'
            os.chdir(project_dir)
        
        # Step 2: æ•°æ®é¢„å¤„ç†
        if not args.skip_preprocessing:
            enhanced_data_root = preprocess_dataset_with_fractional_enhancement(args, project_dir)
            # æ›´æ–°æ•°æ®æ ¹è·¯å¾„
            if args.enable_fractional_enhancement:
                args.data_root = str(enhanced_data_root)
        
        # Step 3: æ›´æ–°é…ç½®
        update_config(args, project_dir)
        
        # Step 4: å¼€å§‹è®­ç»ƒ
        if not args.skip_training:
            success = start_training(args, project_dir)
            if success:
                print("\nğŸ‰ è®­ç»ƒå®Œæˆï¼")
                return 0
            else:
                print("\nâŒ è®­ç»ƒå¤±è´¥ï¼")
                return 1
        else:
            print("\nâœ… ç¯å¢ƒè®¾ç½®å®Œæˆï¼Œè·³è¿‡è®­ç»ƒ")
            return 0
            
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­")
        return 1
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    sys.exit(main())